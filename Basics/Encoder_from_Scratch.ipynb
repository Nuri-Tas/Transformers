{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj6/KIsdUZ4zxLT43E2L/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "832f7d44070448928d09690729d77dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_333cbb826731457088b80307f6bb5641",
              "IPY_MODEL_aa1d08a9ac6546a58852bc244f16bef3",
              "IPY_MODEL_4ea6a286601d4edc861582eca77640e4"
            ],
            "layout": "IPY_MODEL_1b7b3221429748958d358a7025488ccb"
          }
        },
        "333cbb826731457088b80307f6bb5641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6f2447f2de3451f939b460d27636834",
            "placeholder": "​",
            "style": "IPY_MODEL_0ad6434f94e6434e844a04792916deed",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "aa1d08a9ac6546a58852bc244f16bef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1318c581e8f848c4aa0a35a3600b0962",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37b03c399f234e1fb787f84067c3e1df",
            "value": 570
          }
        },
        "4ea6a286601d4edc861582eca77640e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1569115de261438fa318754ea89138dd",
            "placeholder": "​",
            "style": "IPY_MODEL_9ce24b905c1e4c248cbeaa31f68cff1b",
            "value": " 570/570 [00:00&lt;00:00, 33.2kB/s]"
          }
        },
        "1b7b3221429748958d358a7025488ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f2447f2de3451f939b460d27636834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad6434f94e6434e844a04792916deed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1318c581e8f848c4aa0a35a3600b0962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b03c399f234e1fb787f84067c3e1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1569115de261438fa318754ea89138dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce24b905c1e4c248cbeaa31f68cff1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuri-Tas/Transformers/blob/main/Basics/Encoder_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement an encoder layer using Pytorch and Hugginface."
      ],
      "metadata": {
        "id": "vRnsamHKdjRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpDDuMoGetYc",
        "outputId": "59389eaa-8605-40c7-e565-27d5e80081c3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will test the encoder layer on a simple text given below."
      ],
      "metadata": {
        "id": "0ZEHqh6QfZub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tokenizer and config for distilbert-base-uncased\n",
        "from transformers import DistilBertTokenizer, AutoConfig\n",
        "\n",
        "text = \"Building an encoder layer from scratch\"\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_ckpt)\n",
        "# We will ignore the [CLS] and [SEP] tokens by setting add_special_tokens to False\n",
        "encoded_text = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbtD1tHZeu4Q",
        "outputId": "ab8ed8b2-4ad4-420d-a9c4-471e7e03ace5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 2311,  2019,  4372, 16044,  2099,  6741,  2013, 11969]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the embedding for the input ids. The number of embeddings and the embedding dim will be the vocabulary and hidden size of config for bert-base-uncased, respectively."
      ],
      "metadata": {
        "id": "SOu5flzdflzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "config_model_ckpt = \"bert-base-uncased\"\n",
        "config = AutoConfig.from_pretrained(config_model_ckpt)\n",
        "embedding = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "input_ids = encoded_text.input_ids\n",
        "input_embeddings = embedding(input_ids)\n",
        "print(f\"The shape of the embeddings is {input_embeddings.size()} \")\n",
        "input_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "832f7d44070448928d09690729d77dce",
            "333cbb826731457088b80307f6bb5641",
            "aa1d08a9ac6546a58852bc244f16bef3",
            "4ea6a286601d4edc861582eca77640e4",
            "1b7b3221429748958d358a7025488ccb",
            "e6f2447f2de3451f939b460d27636834",
            "0ad6434f94e6434e844a04792916deed",
            "1318c581e8f848c4aa0a35a3600b0962",
            "37b03c399f234e1fb787f84067c3e1df",
            "1569115de261438fa318754ea89138dd",
            "9ce24b905c1e4c248cbeaa31f68cff1b"
          ]
        },
        "id": "TmAjrXtHfGYj",
        "outputId": "602136ae-5c48-4425-f3e5-0bc21b494944"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "832f7d44070448928d09690729d77dce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the embeddings is torch.Size([1, 8, 768]) \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.4857,  2.3533,  1.7693,  ..., -0.3481, -2.2066, -0.2394],\n",
              "         [ 0.5659,  1.3918,  0.0129,  ..., -0.8636, -0.4001,  0.8655],\n",
              "         [ 0.3604, -0.4166, -1.6015,  ...,  1.0989,  0.4959, -0.0708],\n",
              "         ...,\n",
              "         [-0.7831, -0.1895,  0.8419,  ..., -0.1426,  1.5697, -0.0375],\n",
              "         [ 1.0065, -2.8559, -0.2870,  ...,  0.4628,  1.0541, -0.5038],\n",
              "         [-0.8176, -0.7503, -0.7139,  ...,  2.5549, -0.0542,  0.0290]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the scaled dot production function which will first calculate the probability distribution for the similarity between query and key values and return the multiplication of that distribution by values."
      ],
      "metadata": {
        "id": "AVVpoTYBjf-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "import torch\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value):\n",
        "  dim_query = query.size(-1)\n",
        "  scores = torch.bmm(query, key.transpose(1,2) / sqrt(dim_query))\n",
        "  attention_weights = F.softmax(scores, dim=-1)\n",
        "  attention_outputs = torch.bmm(attention_weights, value)\n",
        "  return attention_outputs"
      ],
      "metadata": {
        "id": "Ys1x9SuVgLLo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first define a single attention head which will simply execute scaled dot productions for hidden states. `MultiAttentionHead`, however, will include 12 attention heads in our case, and will concatenate the attention outputs for each head."
      ],
      "metadata": {
        "id": "nqnIm1y1j77b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, embed_dim, hidden_size):\n",
        "    super().__init__()\n",
        "    self.q = nn.Linear(embed_dim, hidden_size)\n",
        "    self.k = nn.Linear(embed_dim, hidden_size)\n",
        "    self.v = nn.Linear(embed_dim, hidden_size)\n",
        "\n",
        "  def forward(self, hidden_state):\n",
        "    attention_outputs = scaled_dot_product_attention(\n",
        "        self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n",
        "    return attention_outputs\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    embed_dim = config.hidden_size\n",
        "    head_numbers = config.num_attention_heads\n",
        "    head_dim = embed_dim // head_numbers\n",
        "    self.heads = nn.ModuleList([AttentionHead(embed_dim, head_dim) for _ in range(head_numbers)])\n",
        "    self.output_layer = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "  def forward(self, hidden_state):\n",
        "        x = torch.cat([head(hidden_state) for head in self.heads], dim=-1)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0QGwOoDijzmV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can confirm that `MultiAttentionHead` returns the outpuf of shape `[batch_size, seq_len, embedding_dim]`"
      ],
      "metadata": {
        "id": "0--F7_Vwkv97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head_attention = MultiHeadAttention(config)\n",
        "attention_outputs = multi_head_attention(input_embeddings)\n",
        "attention_outputs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtih_U_Bkp7R",
        "outputId": "b7828204-3d8b-4ccf-e122-884f506e167a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The outputs from the multi attention heads will be fed to a feed forward layers, which we define below. We also use `GELU` activation function to the first layer and apply a `Dropout` at the end."
      ],
      "metadata": {
        "id": "p3U-fR4RlchO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "    self.linear2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "    self.activation = nn.GELU()\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Km5B4jo9k8gl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can easily confirm that the outputs from the feed forward layers are as expected"
      ],
      "metadata": {
        "id": "0x3NuTnZl1YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ff = FeedForward(config)\n",
        "ff_outputs = ff(attention_outputs)\n",
        "ff_outputs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_pIdqpflxcT",
        "outputId": "5e3aea82-c0c4-4558-d111-f25d728a517c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now add layer normalizations and skip connections both for multi attention heads and feed forward layers"
      ],
      "metadata": {
        "id": "5ThUtozNm6L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayers(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.attention = MultiHeadAttention(config)\n",
        "    self.ff = FeedForward(config)\n",
        "    self.layer_norm1 = nn.LayerNorm(config.hidden_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # normalization\n",
        "    hidden_state = self.layer_norm1(x)\n",
        "    # skip connections\n",
        "    x = x + self.attention(hidden_state)\n",
        "    # apply feed forward with skip connections\n",
        "    x = x + self.ff(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "a8Px17E7mJlk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far we have ignored the positional indexes of tokens. We will now merge the positional embeddings of input ids with token embeddings to take the positions of tokens into account as well"
      ],
      "metadata": {
        "id": "n6kcTEHenL8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.token_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "    # note the 'vocab size' for positional embeddings is the maximum length a BERT model can be used with (512)\n",
        "    self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "    # we will apply normalization and dropout to merged embeddings as well\n",
        "    self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def forward(self, input_ids):\n",
        "    position_arange = torch.arange(input_ids.size(1), dtype=torch.long).unsqueeze(0)\n",
        "    position_embeds = self.position_embeddings(position_arange)\n",
        "    token_embeds = self.token_embeddings(input_ids)\n",
        "    token_and_positions = token_embeds + position_embeds\n",
        "    normalized = self.layer_norm(token_and_positions)\n",
        "    dropped = self.dropout(normalized)\n",
        "    return dropped"
      ],
      "metadata": {
        "id": "6drM1dl3nIn9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The task-independent part of our Encoder layers is now ready"
      ],
      "metadata": {
        "id": "Od3v1dwqnf4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = Embeddings(config)\n",
        "    self.encoder_layers = nn.ModuleList([EncoderLayers(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding_layer(x)\n",
        "    for layer in self.encoder_layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "uoHVOwUCnV7J"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can initialize encoder layers with a simple config and feed input ids to receive encoder outputs that bcan be\n",
        "encoder = Encoder(config)\n",
        "encoder_outputs = encoder(input_ids)\n",
        "encoder_outputs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMqa9wpKnlzg",
        "outputId": "b7acc790-2433-4035-9b17-7b81d037416d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a task-specific layer, such as a classification head, is a breeze. Conventionally, only the first result of sequence is taken into account in classification tasks in NLP."
      ],
      "metadata": {
        "id": "HsUui1z6n_3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerForSequenceClassification(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(config)\n",
        "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # only take out the outputs corresponding the first element in the sequence\n",
        "    x = self.encoder(x)[:, 0, :]\n",
        "    x = self.classifier(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "kpPyoNbLn-kv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can adjust the number of labels in the config file to our specific problem\n",
        "config.num_labels = 3\n",
        "model = TransformerForSequenceClassification(config)\n",
        "# We will get 3 logits value corresponding to each class label\n",
        "model(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxovHK1-oU95",
        "outputId": "0483e1fc-8993-4e74-dfb8-228d306b2863"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.1153, -0.6365, -0.3180]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cN8F14ozoW8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}